{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Try2-Arabic.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gyf6q_gfXC9s",
        "colab_type": "text"
      },
      "source": [
        "Based on https://medium.com/@ngwaifoong92/beginners-guide-to-retrain-gpt-2-117m-to-generate-custom-text-content-8bb5363d8b7f"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vYFpaayHqIM",
        "colab_type": "text"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTUS01SXGmGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d3bb723-2885-4698-b8a2-502132b4da7c"
      },
      "source": [
        " ! pip install --upgrade fastai2 fastcore==0.1.38 fire tqdm regex requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/50/2f37212be57b7ee3e9c947336f75a66724468b21a3ca68734eaa82e7ebf3/fastai2-0.0.30-py3-none-any.whl (179kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 102kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 122kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 133kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 143kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 153kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 163kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 9.5MB/s \n",
            "\u001b[?25hCollecting fastcore==0.1.38\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/2d/977648ad8b01b557ca925da006b9a8ec713008b0a450413aac75612e71d5/fastcore-0.1.38-py3-none-any.whl\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.2MB/s \n",
            "\u001b[?25hCollecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25hCollecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/f2/b3af9ce9df4b7e121dfeece41fc95e37b14f0153821f35d08edb0b0813ff/regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660kB)\n",
            "\u001b[K     |████████████████████████████████| 665kB 17.4MB/s \n",
            "\u001b[?25hCollecting requests\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/1e/0c169c6a5381e241ba7404532c16a21d86ab872c9bed8bdcd4c423954103/requests-2.24.0-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai2) (0.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from fastai2) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from fastai2) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.38) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses in /usr/local/lib/python3.6/dist-packages (from fastcore==0.1.38) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from fire) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from fire) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai2) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai2) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2) (3.1.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=53a67540d602c023684fa587aba266de7b23a028ced84dc554d32f55e733b2e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built fire\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.24.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fastcore, requests, fastai2, fire, tqdm, regex\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed fastai2-0.0.30 fastcore-0.1.38 fire-0.3.1 regex-2020.7.14 requests-2.24.0 tqdm-4.49.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAkkf65agw6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "d9361992-d5f4-4fc2-ce37-92fcdf81572b"
      },
      "source": [
        "! pip install tensorflow==1.15 toposort"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 33kB/s \n",
            "\u001b[?25hCollecting toposort\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 52.0MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=e9199c151e9a2af8bab3bf57b88d9b297c96e88b71222a737b754af3fe9debdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, keras-applications, tensorboard, gast, tensorflow, toposort\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1 toposort-1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNOzy0FsGwaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1ebf9f1d-839b-42e6-bb75-efd9d2fed6ae"
      },
      "source": [
        "! git clone https://github.com/nshepperd/gpt-2\n",
        "! cd gpt-2 && python download_model.py 117M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 375, done.\u001b[K\n",
            "remote: Total 375 (delta 0), reused 0 (delta 0), pack-reused 375\u001b[K\n",
            "Receiving objects: 100% (375/375), 4.43 MiB | 1.24 MiB/s, done.\n",
            "Resolving deltas: 100% (204/204), done.\n",
            "Fetching checkpoint: 1.00kit [00:00, 880kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 54.5Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 808kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:10, 46.7Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 4.35Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 55.9Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 36.8Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HScrlu4FHmol",
        "colab_type": "text"
      },
      "source": [
        "## Get Arabic Wiki text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbP3Ix42HI5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d8d8cc4e-9ad7-4df9-b5a0-6e24e73cedb0"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/mapmeld/fastai-projects/master/nlputils_fastai2.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-19 13:15:43--  https://raw.githubusercontent.com/mapmeld/fastai-projects/master/nlputils_fastai2.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4601 (4.5K) [text/plain]\n",
            "Saving to: ‘nlputils_fastai2.py’\n",
            "\n",
            "nlputils_fastai2.py 100%[===================>]   4.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-19 13:15:43 (71.7 MB/s) - ‘nlputils_fastai2.py’ saved [4601/4601]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsjnv_ewHlta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a6965bfd-6f81-48ca-9216-6d780bcd75b9"
      },
      "source": [
        "from fastai2.text.all import *\n",
        "from nlputils_fastai2 import * \n",
        "lang = 'ar'\n",
        "name = f'{lang}wiki'\n",
        "config = Config()\n",
        "data_path = config['data_path']\n",
        "path_data = data_path/name\n",
        "path_data.mkdir(exist_ok=True, parents=True)\n",
        "get_wiki(path_data,lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "unzipping...\n",
            "extracting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVZo97ELHtUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "7731ce15-60de-4601-b0f0-bed9edfca716"
      },
      "source": [
        "dest = split_wiki(path_data,lang)\n",
        "dest = path_data/'docs'\n",
        "for file in dest.ls()[:5]:\n",
        "    print(file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100000\n",
            "200000\n",
            "300000\n",
            "400000\n",
            "500000\n",
            "600000\n",
            "700000\n",
            "800000\n",
            "900000\n",
            "1000000\n",
            "1100000\n",
            "1200000\n",
            "1300000\n",
            "1400000\n",
            "1500000\n",
            "1600000\n",
            "1700000\n",
            "1800000\n",
            "1900000\n",
            "2000000\n",
            "2100000\n",
            "2200000\n",
            "2300000\n",
            "2400000\n",
            "2500000\n",
            "2600000\n",
            "2700000\n",
            "2800000\n",
            "2900000\n",
            "3000000\n",
            "3100000\n",
            "3200000\n",
            "3300000\n",
            "3400000\n",
            "3500000\n",
            "3600000\n",
            "3700000\n",
            "3800000\n",
            "3900000\n",
            "4000000\n",
            "/root/.fastai/data/arwiki/docs/جغرافيا سوريا.txt\n",
            "/root/.fastai/data/arwiki/docs/جويس كيلمر.txt\n",
            "/root/.fastai/data/arwiki/docs/زواج المتعة.txt\n",
            "/root/.fastai/data/arwiki/docs/التعليم في سلطنة عمان.txt\n",
            "/root/.fastai/data/arwiki/docs/نيكولاس غارسيا مايور.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hTI0UxrJI0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "open(dest.ls()[1], 'r').read().replace('</doc>', '').strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EWRmJnsIcyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "op = open('/content/combined.txt', 'w')\n",
        "for file in dest.ls():\n",
        "    tmp = open(file, 'r')\n",
        "    op.write(tmp.read().replace('</doc>', '').strip() + \"<|endoftext|>\\n\")\n",
        "    tmp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ21VIiIXH7E",
        "colab_type": "text"
      },
      "source": [
        "## GPT-2 tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SsoCqIqUQRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp gpt-2/encode.py gpt-2/src/\n",
        "! mv gpt-2/models gpt-2/src/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dsi1zSWU_cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp /content/combined.txt ./drive/My\\ Drive/mlin/ar-combined-wiki.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rcvBiV7Vli0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm combined.txt\n",
        "! head -n 600000 ./drive/My\\ Drive/mlin/ar-combined-wiki.txt > combined.txt\n",
        "# tried again with 2 million lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys0oXIBCHzWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "31faff2f-9d84-4069-d907-09c99f3936e6"
      },
      "source": [
        "! cd gpt-2/src && python encode.py /content/combined.txt /content/wikid.npz\n",
        "# tried again with 2 million lines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-11 04:45:47.971275: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Reading files\n",
            "100% 1/1 [07:07<00:00, 427.07s/it]\n",
            "Writing /content/wikid.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p42yHLZcX222",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp ./drive/My\\ Drive/mlin/arwiki.npz ./wikid.npz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEXgSlApbOZb",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj_8ok3lfIpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp gpt-2/train.py gpt-2/src/\n",
        "! cd gpt-2/src && python train.py --dataset /content/wikid.npz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uZ7JNJebR9J",
        "colab_type": "text"
      },
      "source": [
        "## Storing in models and in Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsIOy6PXaQcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -r gpt-2/src/models/argpt\n",
        "! mkdir gpt-2/src/models/argpt\n",
        "! cp gpt-2/src/models/117M/encoder.json gpt-2/src/models/argpt/\n",
        "! cp gpt-2/src/models/117M/hparams.json gpt-2/src/models/argpt/\n",
        "! cp gpt-2/src/models/117M/vocab.bpe gpt-2/src/models/argpt/\n",
        "! cp gpt-2/src/checkpoint/run1/checkpoint gpt-2/src/models/argpt/\n",
        "! cp gpt-2/src/checkpoint/run1/model-200* gpt-2/src/models/argpt/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAP8-onUDYHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -r ./drive/My\\ Drive/mlin/argpt\n",
        "! cp -r gpt-2/src/models/argpt ./drive/My\\ Drive/mlin/argpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SomBwF1AzOx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "46413559-e34c-4b85-b2d9-da01e4008b2c"
      },
      "source": [
        "! ls ./drive/My\\ Drive/mlin/argpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t  model-200000.meta\n",
            "encoder.json\t\t\t  model-200820.data-00000-of-00001\n",
            "hparams.json\t\t\t  model-200820.index\n",
            "model-200000.data-00000-of-00001  model-200820.meta\n",
            "model-200000.index\t\t  vocab.bpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkFO55SGIE-_",
        "colab_type": "text"
      },
      "source": [
        "### Restore model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b27qX7DOITNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir gpt-2/src/models\n",
        "! cp -r ./drive/My\\ Drive/mlin/argpt gpt-2/src/models/argpt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svxw_X1LbbQT",
        "colab_type": "text"
      },
      "source": [
        "## Test that Arabic comes out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4691KSvkZ9Dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "59e326fd-860b-4d96-def4-2e65e8b504f5"
      },
      "source": [
        "! cd gpt-2/src && python generate_unconditional_samples.py --model_name argpt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_unconditional_samples.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-09-20 04:31:41.806830: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-09-20 04:31:41.836600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.837282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-20 04:31:41.837575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-20 04:31:41.838747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-09-20 04:31:41.839942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-09-20 04:31:41.840255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-09-20 04:31:41.841573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-09-20 04:31:41.842532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-09-20 04:31:41.845574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-20 04:31:41.845702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.846304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.846862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-09-20 04:31:41.847251: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-09-20 04:31:41.851640: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n",
            "2020-09-20 04:31:41.851926: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15d3480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-20 04:31:41.851957: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-09-20 04:31:41.945916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.946664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15d3640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-09-20 04:31:41.946700: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2020-09-20 04:31:41.946867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.947402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-09-20 04:31:41.947455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-20 04:31:41.947475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-09-20 04:31:41.947486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-09-20 04:31:41.947501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-09-20 04:31:41.947526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-09-20 04:31:41.947539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-09-20 04:31:41.947552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-09-20 04:31:41.947603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.948231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.948787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-09-20 04:31:41.948859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-09-20 04:31:41.950199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-09-20 04:31:41.950228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-09-20 04:31:41.950235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-09-20 04:31:41.950339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.950950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-09-20 04:31:41.951464: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-09-20 04:31:41.951494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15024 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "WARNING:tensorflow:From generate_unconditional_samples.py:54: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:166: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:70: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From generate_unconditional_samples.py:63: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2020-09-20 04:31:46.910884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "الاقلية 18:30 بقدم تابعاً بعد الحرب\n",
            "\n",
            "الاقلية الثانية 11:30 بقدم تابعاً بعد الحرب\n",
            "\n",
            "الاقلية 21:30 بقدم التابعاً بعد الحرب\n",
            "\n",
            "\n",
            "اقلية الأنثربولس\n",
            "\n",
            "اقلية الأنثربولس هي إشارات ومجموعات إلى 11 عندما تقوم المجموعات المفتاحية بأنظمة التحليل الأول للتصميم الحارة ( descammed) والثاني والثالث والعشرين \n",
            "\n",
            "اقلية الشباب (اقلية الآلية الحتمراء)\n",
            "ابتداء من 2009 - 2011\n",
            "كانت مدارس ونظام الشباب في الأرض بحلول عقد الستينيات.  خلال حكومة الأنف في أوروبا شملت في الإنجاد بالأسواق والعمل في السعودية وبعض الدول الأوروبية والأندلسية. في مدارس الشباب وبعض الوفاق على الحكومة البارزة.\n",
            "ثم  كانت اتفاق ملحق إلى الألمانية والأمم السعودية.\n",
            "كانت اجراءتها بنظام السرطان في الأرض بالأسواق والأندلسية في إنجاد العديد من المناقشات الخيرية ومنع الاتصال بالأعداد في قانون حاكمتي عرشي الأندلس.\n",
            "\n",
            "ثم انتهى عام 2001\n",
            "عملت في الأنشاء التالية وجود النخبة والعضوية الصوتية والفوسفات المضادة \n",
            "والحداد، والشك، والأداء. \n",
            "\n",
            "حجم الأعداد التالية كتابة على مستوى آخر شكل نخبة من علماء حقوق الإنسان كان من النفس كما هو وقارب معتمديه التي تعتمد على وضع الإنسان لتكون بشرط فحص إقبال الكوار\n",
            "\n",
            "\n",
            "عمود الملحقين\n",
            "\n",
            "عمود الملحقون هو انبعاث وت\n",
            "======================================== SAMPLE 2 ========================================\n",
            "2، وهو مركب موزيلا.\n",
            "\n",
            "كما هو موزيلا يدل على أن الموسم الذي وقع في فوج المسرح، والمحدودة مجموعة من المتخصصين من هودجر هاوس. هو جهاز موزيلا تقريبا. في حين أنه وجد هو اثنين منوبة كالعامة. وجد ضعيف؛ وهو فنان ذا يستخدم في اغنية الدردشة الرعبة الفرنسية ووجود أي حد يسمح أن يكون شبه قادر على الحد من حدة نفسيه.\n",
            "\n",
            "إلا أنه لا يزال هو موزيلا يقودها طمع الدهر. لانه لا علام تظل تحقيقًا بدلًا من أن لا نهار على المنافسة. يقود طبيعي كثير من سكار. ألبربي أن أصحاب هيلين وفرد قد توجد على الدهر، ومن خلال تحديد أي تطبق على الخدمة النسائية للأطمئنان.\n",
            "\n",
            "على مستوى الأراضي التبادلية، جرت بلدية على جسر قشتالة فرانكلين وشاي أول متنزه بآخر مرتفع.\n",
            "\n",
            "ضعَب رجلًا وغنمًا؛ قال رجل أثار ألف ماستر رومه في أكتوبر 2017 في معتصف الفلكلوري التاكيتي محتل جدران الجزء الأخير من مواطنه.\n",
            "\n",
            "تناوب فيما بعد لحادثة أعطت المخيم مستويات متناوبة، مثل المفاوضات في شكل سرطان التعليم. في المل، يمكن للموزيلو أن يعرض المرض عمل بسيط ليبدأ بيتاً بفلتف الفيلسوف الهام الكبير المنحدر؛ حيث بسبب الضغط الأكثر ربحاً هو موزيلا.\n",
            "\n",
            "في الواقع، تستخدم السرية وبسي\n",
            "======================================== SAMPLE 3 ========================================\n",
            "استغرورد باي ‡بي النمر ي بالربع الثالث والثلاثين سنة يشار إليهم بالأخلاق الداخلية إلى حد ما إذا كانت سلاسل أماريا المحلية Associationature, ولكنه لم يعشر البيانات المذكورة لهذه الأطوار.\n",
            "هناك العديد من الشيوخ دافعوا القوة لأنهم غيروا جدت، بل يوجدوا خواص مقاومين سياسيين:\n",
            "\n",
            "\n",
            "حسب المعيار الإلكتروني, والأخلاق الداخلية الشيوخ يمكن لهما أن يكون أوجه الشيوخ على كل شيء داخل حلقة النمر. وبهذا نعرف أنه قد يكون كل من يمنى \"الغرام\" (ولكن النمر الذي بدق الحقيقة أو.. \" نمر : قوى يتبع\") ويوجد به الحسب ان يكون فيه مجال داخلي، وذلك سواء بإستخدام الدانوب والأثاثات التي تتشوبين الذرات السريرية.\n",
            "يُشغل سريرى الشيخ منزلات حسب المعيار04 داخل وخارج.\n",
            "الشيخ منزلات سريرية تأخذ في قنوات تنظيم دخيل على طول قابليتها.\n",
            "\n",
            "\n",
            "\n",
            "سكيبتيو\n",
            "\n",
            "سكيبة، حركة حقوق الإنسان\n",
            "\n",
            "أحد مؤسسي سكيبتيو على طول طريق لتعزيز عدد الطرق الجانبين السبع والموصلة.مطلوب من عدد السباقات مستقبلي سكِيبت، وكانوا عبارة عن السكِيبات الآدمية وقطاع البلدون على الجانب الخارجي من السكِيبة.\n",
            "\n",
            "النواة الأولى التي بلدت عين البعمان والثانيين.\n",
            "\n",
            "في عام 1957 أمر بتعيين إصدارات عن الخلية التي جرت في المرّ في عام 1957 امتلك\n",
            "======================================== SAMPLE 4 ========================================\n",
            " لا يعرف وجود مواصفات المسؤوليين تمامًا مهمًا في كونها أحد أربع كواكب خاصة.\n",
            "الموضوعات في مجلس الوزراء عن طريق تشخيص تسجيل المحيط الأطراف من الترشح - في حوالي السبعينات- في محاولات فردية. بالنسبة لمجلس الوزراء فإن الدورة تبيل أو إسقاط دمار الإنترنت. فإنه يمكن أن يخضع لفرط العودة المشتركة في فنزويلا وغيرها؛ كما يمكن ملاحظتها استقرار الدورة حتى يقدم الوزامات الرغبية المتولدة بأن الدورة في البلدان الأخرى يميزان في أدلة حل الموضوعات العشوائية المتمثلة في اختيار أعراضها العشوائية اللة فكل موضوع ملاحوظ في نفقة مكملة. في حالة الفوز كذلك، ومنذ ذلك الحين أيضاً ، تتمثل أدلة موضوعة الموضوع في عدم التوقيع الحالي. التمثيلات المجتمعية العرقية والاجتماعية، متطورة كلثانية وبالتالي توفر تتمثل في انهيار الخريطة والحدود البيئية الحرجة لتصل إلى 4000 نسمة ، من أغلب إجمالي الاحتياط على المريض. ويمكنك البحث عن عدم التصلب بالمواد المستهدفة ذات العينة المخصصة من خلال تحول تحت المعاينة في الدمار.\n",
            "\n",
            "في عام 2013 كان المصلح الرسمي دير نيكولاس دير الوطن الجنسية المحلية القابلية عنه. في الحقيقة بسبب الباحثين النسخة الأمريكية حديثًا نهائياً ، مضيفًا. في أعقاب م\n",
            "======================================== SAMPLE 5 ========================================\n",
            "\n",
            "\n",
            "إنوكلير إشتيك كوك إنوك إريك إريك هي من أقل الأنواع الأساسية لمعالجة الإنسانية: توتر بين كلا الديكتانيين. أُنشأت أغلب القراءات أو قواعد فلسفية في مونتريال رحلة إلى محطة البنكرياس جسدها بتوجيه أنواع مختلفة من الأنواع المختلفة ووثيقة مثل الباسك و الصوب لقنوات الاسماك الأرضية التي تبدأ ليس إلى رغم فحص الدماغ أو الدم.\n",
            "\n",
            "في اتجاه الشمال، يوجد في اللحاقتين هو نذق من ألبوم \"أسفهط\" السنوي القديم على حائط المسيح وبحيث يعتبر هذا النوع من أشكال السيطرة والسلسلة \"(ت) .\n",
            "\n",
            "الاقتصاد الذي يقتصر المفارقات له مزود والإعادة بفريق الرضاعة وبحيث يعمل على إنشاء جميع أنواع الفيزياء (ب) أو (الآيفا) على تحويل الساق وعلى ذاكرة انواعها منه مثل السربية الحكومة. من الصمام انهم يمضي على أن يمثلوا أي أنواع مختلفة منها ( الوثق العميد) بتنويع مصطلح \"أسفهط\".\n",
            "\n",
            "يعمل فهم الرجل الذي يشكل الفيزيائيون والبيطرى \" إشتين \" متعدداً على التجار التاريخ يكون أول ملح للأم \"ت\"، \"أسفهط\"، \"شتاء المونسي\"، \"توأمون\"، \" شتاء على شعوب، الإصابة بالصبرة ...عرضل\"، \"تصدى\"، \"على المعادلة\".\n",
            "\n",
            "أكد أهمية تطهير الأسلاف على طريقة تخريب قوة أو أسبوعية، في كثير م\n",
            "======================================== SAMPLE 6 ========================================\n",
            ": 27)\n",
            "\n",
            "هذا السابق وفقا لأول مرة هو حوالي بعض الغناء اللواتي جعلها غير شرعية. وفي عام 1950 انكملت مؤسس نظام تسمية التحول (دليل النظام اللاجئي في غشاء الحماس) وقال في أغلبية هذا الاعتبار الأساس إن البشرة يستغني في جميع التورات بخاصة على القدرة على الاعتبار، ففي آخر سنوات ذلك سطر الابن قدرته على توافق حل خلق المرأة\n",
            "\n",
            "وبين بعض السلع خاصة في السابق ويكون هناك حاجة 12 ألف حرقة إذا ما ما كانت من الضرورة بهذا السابق ذات أنواع بالنسبة لسلع السندين إللى السلع توقيف بهذه الجهود مما أخذ هذا السابق بمتلازمة وغيرها من أجل الاستمرار وتمتلك قبل أن تتسن، ثم تفادت هو إذا سبقاً فإن لا يوجد بوحدة الماي سبقه باطلاع من السلع السندين.\n",
            "\n",
            "ساعد هذا السابق على طول ثروة من هيئة التشخيص عندما سقط من السلع فتح أو سقط من ترددات عالية التواويع.\n",
            "\n",
            "إن ذاك يعني كل مبدئي عوامل التطور أو إنتاج الحد الذين أخذوا الجهد هم المتناسبون في حومين دوليين أو فضاء في علاقة مع لوحة حياة داخل الأدمة. فبعض أنواع السلع هامة ومزيج من قانونيا بصرف الطريق، فرأى القانون واخذ لوحات عالية أو عكس عنصراً.\n",
            "\n",
            "\n",
            "بي سي ديزمون\n",
            "\n",
            "بي سي ديزمون ، من مواليد 30 يناير 1971 في بنغازي مثل: سيرما (2005 تي):\n",
            "======================================== SAMPLE 7 ========================================\n",
            "د ليندسيون (1 أكتوبر 1891 في المملكة المتحدة - 29 مارس 1950 في الولايات المتحدة) هو لاعب كريكت بريطاني وبريطاني (وحمل سابقاً جنسية المملكة المتحدة لبريطانيا العظمى وأيرلندا). لعب مع .\n",
            "\n",
            "\n",
            "دونالد أوكونور\n",
            "\n",
            "دونالد أوكونور (5 ديسمبر 1894 بنيكلاس في المملكة المتحدة - ) هو لاعب كريكت بريطاني. لعب مع .\n",
            "\n",
            "\n",
            "مايكن سواريز\n",
            "\n",
            "مايكن سواريز (19 أكتوبر 1942 - ) هو لاعب كريكت أسترالي. لعب مع .\n",
            "\n",
            "\n",
            "غاري سونغ\n",
            "\n",
            "غاري سونغ (1 يوليو 1977 في أستراليا - ) هو لاعب كريكت أسترالي. لعب مع و.\n",
            "\n",
            "\n",
            "ماركوسا ميلر (لاعب كريكت)\n",
            "\n",
            "ماركوسا ميلر (17 سبتمبر 1794 - ) هو لاعب كريكت أسترالي. لعب مع و.\n",
            "\n",
            "\n",
            "ماركوسا كارلمان\n",
            "\n",
            "ماركوسا كارلمان (23 يونيو 1835 - ) هو لاعب كريكت أسترالي. لعب مع أستراليا الجنوبية.\n",
            "\n",
            "\n",
            "برنارد فالي\n",
            "\n",
            "برنارد فالي (21 يوليو 1875 - 5 سبتمبر 1945) هو مفاوض وصحفي ولاعب كريكت أسترالي.\n",
            "\n",
            "\n",
            "بيل شيد (لاعب كريكت)\n",
            "\n",
            "بيل شيد (12 يوليو 1907 في المملكة المتحدة - 27 مايو 1968 في المملكة المتحدة) هو لاعب كريكت بريطاني (وحمل سابقاً جنسية المملكة المتحدة لبريطانيا العظمى وأيرلندا). لعب مع .\n",
            "\n",
            "\n",
            "لورينزو موراي (لاعب كريكت)\n",
            "\n",
            "لورينزو موراي (1951 - ) هو لاعب كريكت نيوزلندي.\n",
            "\n",
            "\n",
            "رونكو أنتونيو\n",
            "\n",
            "رونكو أنتونيو (7 أبريل 1904 في المملكة المتحدة - 21 يوليو 1976 في المملكة المتحدة) هو\n",
            "======================================== SAMPLE 8 ========================================\n",
            " Un gerzogensisch ürefondsienswegenes. (D. Biol. U integrate.)\n",
            "\n",
            "09.27.2008 쿤폘이태\n",
            "\n",
            " Finland Film English -eeinen Ungerzungs Sketch.\" (D. Biol. U Integ 920.)\n",
            "\n",
            "16.9.2007 95\n",
            "36\n",
            "SIEC 3869/SIECID-I- flares- 31121198.org\n",
            "\n",
            "\n",
            "\n",
            "ميتي سلوني (توضيح)\n",
            "\n",
            "\n",
            "\n",
            "الريتشارد رينكسونك\n",
            "\n",
            "مؤسس الحركة الإنسانية الطبية الرقمية ريتشارد رينكسونك الأول كممثل لحركة عمالية عشوائية من�فضاً في القانون الحكومي، عضو في علم الأسجوعات، كما يعرف مجموعة عمالية مضرة الاستثمار. جاءت تفاصيلها ذات الضعف الطبي في السياسة الأمريكية للحرارة، بحسب اختصار مؤسسة تربوية و94، السابقة، تربوية و 98، الاستثمارية، تخصص عائلي، وورشة تحلل في المستقبل. يتمثل توضيحًا في مجلس التخصصات كهربائيا تاريخيًا يمكنها اختلافات فيما بينه، أيضا مجلس تخصصات في الحياة سواء من ورشة تخصص في الحياة أسطوانية أدق بها السوق. في 7-10-2007 قامت الباحة العامة علم نفس القانون الصحي في الحياة، سعية لدعم أو تثبيت القانون لمنع سلويك، وبعد فترة ستار (2006-2007).\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "جلست استشارية كوسوفانيتية\n",
            "\n",
            "جلست استشارية كوسوفانيتية هي عادة الامثلة التي تعني استقطاب طيفي الوجه، وأنها استشارية بقوة ثم تفاعل دوار ناسا مع استشاريًا معًا. في عام 2012، اقترحت بعض العوامل 101 و again عندما تكون دقيقة تهدد ديني. في يوليو 2015، تكون ال�\n",
            "======================================== SAMPLE 9 ========================================\n",
            " لاحظ مال تشكيل الحواجز والأعمداء عند مقتل 24 امرضاً للاستخدام من مسحوقات بسيطة منها الرأي. وبلغ حوته الافلام في رحلته إلى مركز تنظيمي خارج الأوروبي أدت إلى إدارة تشكيل لاحظ في مساحة أكثر من 26, Elaine concentrating EauCon lending.\n",
            "\n",
            " Good out ofoghi الفيديو يتألف من الموحد الإسكندرية انتمى لتشكيل استيراد أفلام غنمية. ما داّن انتماءً من الموحد الأفلام الرقمية، يلتقي خدش انحراف للغة 65 Enoch Cavaria منه.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "قرن مغني\n",
            "\n",
            "القرن (\"Ainfeldacterium\") التابع للإغناطيق الجبلي للعبودية القمحة على التواجدية الداخلية مولاي الكم، قرن الكثير منه تصيب 5 أقمشة صيدليف كهربائية، بالإضافة إلى رؤيته لإكتشاف مظهر الذكاء .\n",
            "\n",
            "يتميز القرن الأول للتحقق الذي يمتلك قسمًا من الدجاج العربي Proteosts بمراقبة الزيادة في نطاق واسع والزيادة الذي يتغذن من عدد الشخصيات المحلية، وتشكيله هو اختراع شركة ريورن.\n",
            "\n",
            "يحتمل أن يكون اسم هذان كاغنر منحنجين في الكون، يجمع حضارة المكان الذي يتحمل شديدة التوابل في بيته المراد الرئيسي التابع للقرن.\n",
            "\n",
            "و عمليا باسم القطر يجيد التجميل، فهو يسأل ثلاثة منه عند عقيدة ريون ليتحدث عنده! و يقارنين بأنه لن يطرأ عليه قبل أن يبدأ الكاحلهم التوغل في ٷبقتين.\n",
            "و يرقد أن الكون �\n",
            "======================================== SAMPLE 10 ========================================\n",
            "افق الهيمرة بطريقه لعدد كتبها 5 سيفاً (إذا ما قورنكاه؟.) أنفق المتصل على الطريق (أو غامض) ثم انفجر عُرَض طولها ثلاث سيء (\"%).\n",
            "\n",
            "لا يزال تقريباً من عدد تذكاري إلى سنة إذا استطعأنها الطعاسة في أوجي من العدوة بواسطةב هيمر أيرن باري مؤاب، فإن المطبخ العثماني لوawa 2011 في أوجي أكثر من 10 عقس في شدة دكم الزوب، مضاربة شديدة البيضاء 3 وضع مرض. فتفسرَ أحياناً زبقية ت في أوجي بلباق، السكان 4 والجزيرة التي بين 5 سيفاً إذا أصبحت زبقية تبنى، مؤلفة بأن اليونيسيون، في هذا النوع، الزبق يحظر ثلاثة آباء سي. بلباي مع أصوات من كل طريق، مما حدث حتى سنة 2011 ما أصبحت الباي منصة طول مقالة ثلاث إذا أصبحنا مؤلفاً، مضت فيي هذا النوع. أشارت اختصاصية اسم المطبخ العثماني التي يتحدث بها اليونيسيون سي. يوزين(سم يوزين)ركلي بعام الماضي.\n",
            "\n",
            "في أول مرة مع يوزين/ سي فرسان/ بروماتنس سنة 20/06/2011 استطاع المطبخ العثماني مرضياً بسبب خلاف اليوسف. تبسط ميل سترورز من اليوتيوب أصبح معروفاً جيداً آخر. أوقف متسبط بمطبخ العثماني لوبيت شرقاً. كتب جويليوم كويك تصريح من قبل المسؤول للعمل على الجدران. كان الباي تصريح من إنذار آفشما\n",
            "======================================== SAMPLE 11 ========================================\n",
            " 8\n",
            "\n",
            "كالوي ياندر لمعرض كرة قدم لتبادل الشيخ إيكو بولاية نيفادا الزراعية هو الكثير من العمليات الاجتماعية في التخطيط الذي يحوي الاجتماعي الفعلي وتصنيف المجتمع من آخر للتدريس على الشيخ هويلي موناكن، جولدينان وهي نواة للإنشاء والتأمل في القيود الفعالة وللبيئة. ويستخدم كالوي في وضع الإنشاء التنظيمي لكسر السمو المحلي والإنشائي، فعادة له مواد الأشجار الضمنية الوربية والعمومية تحتاج إلى حد سواء أو بين عرضي بين السمو الشخصي واربع تلك الذي يجد اللون.\n",
            "\n",
            "و تساهم في نظرية الأسماك بسبب ارتفاع في السمو اللوني، والإنشاء الإقطاعي ثنائي الفوسفات وثنائي الجسم، وغيرها من أماكن في اليد والسليك، حيث يمثل هذا الأيض مصالح للسليك وهو ما يجلس في اتحاد مركز الشرطة ومركز دواجنها، ويستخدم عدة مصالح لإعادة سبب المهددين في السمو. ولهذا السبب يتطلب مصالح البين السهروقلونية عن طريق تفكير الأسماك بشكل كبير ؛ حيث يتم تفجير الأسماك اللون معظمها من شرطة الطيران.، وواحد من الهوائيين تختلف الأسماك الأعماق عن السهم المتقدم من مشاهدة غالبية الحيوانات.\n",
            "تتم العديد من نظرية الفوسفات من كِل منطقة ربط مارجايه على امتداد وتستوير عبارات يطيق الواقع على المنطقة المخصصة\n",
            "\n",
            "وفي\n",
            "======================================== SAMPLE 12 ========================================\n",
            "م تشغيله عمل كفيل في مجلس أعلى معايير الحدود الجزائرية\" حوالي 1803. كان هو أن القادة الجزائري ذلك لم يبدأ عام 1873 واستمر مع بداية ستونوولوغ، وهو فيلسوفاكين لافي على عكس الوثائق المضادة: كاد أاسيناشم وجيجنا، وطيرون، وفان موسرا، أتىبيس وتحديد العلاقات المعارضة.\n",
            "\n",
            "كان يحظى في 1512 أسم فئة إضافية في بلده والبواحي حيث إن معارضة بيلوبيا قد استقر معهم من مضيق إيسناماندو في 19 من شهر بليو إيسنام. غاب على الجزائر فريق نفسه بأولاده لخطط مع نفسه في 1921-1923 ة.اكي -كانت الحرب تتبع جدته في العاصمة بوليزانا حيث تبتعد زعنفتها الموزعة؟\n",
            "\n",
            "توفيت في 12 يوليو إيسناما، 1927.. يقدر عدد سكانها بسبب ذلك، تقريباً ويحتاجها إلى لإيسنام، ولا يبقى إلا أحد الكنائس الألمانية.\n",
            "\n",
            "شارك في 1 مايو، 1935 بتصوير ما يقارب 96 مليون دولار أميركي لمؤسسين من قتال خيسية مهنة كبيرة.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "نجي السنديان (توضيح)\n",
            "\n",
            "َ بلدة نجي السنديانِ التَّوَضِيَّةُ السِنْدِيَّةُ عَلَيّْةُ تُقَدَّرُ بحَوالَي ثَانيَاتَ الْقَطْنِيّةُ الّْتَّابِعُوَيّةُ بلدةُ نجيَةُ عَلَيّْةُ تُقَدَّرُ بحَوالَي 10 آلِيَاتَ (115 ميلاً و 114 ميلاً). تِستخدم في التقويم الرِبْعَ، وتَقَدَّر\n",
            "======================================== SAMPLE 13 ========================================\n",
            " لاجوستي اوليها هذه الفكرة، التي حدثت من تسميتها في آدامشت فكرة قوية خارجية.\n",
            "\n",
            "تعد مسقحيتة اوليها أكبر المسقوط في المادة الكيميائية من مسقط رأسه في التسمية أو في التسلق أو القراء المسقوط الذي يقوم به القلق في حلقة. قارنت محلية تقريبيم انها تكون الحلقة وهذا عوامل غير طبيعية مختلفة تجعلها قادرة على تركز بحث\n",
            "\n",
            "تتابع مساحة قاعة ضعف المعالجة الموجهة إلى قدر مضاعف نباتي وتزدوي التكاثر ويمكن تفسير وهذه الميلية سوف تتوتر الرأس بالضعف إلى مكانا ضد قبو كلا المضاعفات الأخرى.\n",
            "\n",
            "لكن عدد من الفضولى، يتم علاج شدة الفشل بالكثير لا يستخدم قاعة نوعية النوع الوحيد الذي يقدمه فصل الضيف والألم /بي اللحم- اللحم والجمل في الصناعة بشكل اجتماعي نظرًا عنه بالإهمال من خلال الوريد التفضيلي وأخيرًا يصاب بثمن من النوع الأساسي.\n",
            "\n",
            "\n",
            "\n",
            "طبيعة جديدة استخدمنَ الضيف\n",
            "\n",
            "طبيعة الجديدة هي نوع من أصل تشريط الطبيعة، وعادة يكون لها لونا في النوع الثنائي في نوع الأحسائية.\n",
            "\n",
            "تشتمل الطبيعة على ثمن أقل استخدماتٍ الطبيعة مناسباً لكل ولحة في شكلها المجزوء في فصل الضيف.\n",
            "\n",
            "يحتوي الطبيعة على خلايا خلايا اخترين، وأخذ اختر وغيرهم من خلال الأخذ عندما يفترض �\n",
            "======================================== SAMPLE 14 ========================================\n",
            "ان\n",
            "\n",
            "تقع ساحة تربية تقع في منطقة صحة البداء من الجهة الأوروبية وتتخذ منذ بدايتها هامة وكف الحروب والمنضمنين إلى سوريا، ويبلغ عدد سكانها 2 أميال يوما وعدد سكانا في 1,500 نسمة، اختصاراً للإستقلال المهدل لجاذبتين مقابل النهر. وقد استشهد البلد المدرع خلال هذه الفترة اسكتلندا ثورة واحدة من القبائل السهل تلويونايت تدريجيا اربعة فول ذو صلب ساكن بالسهل، وهي تتمثل فيما يقوم بالتصنيع الفول، وقد استعمل الوقت الحالي في الإمبراطورية البيزنطية كمقر سنوي مكثف ويحمل الشئ التجاوي لحفا، تشبه القمة حيث الحروب العربية والبحرية في اليوم التالي.\n",
            "\n",
            "كانت القبائل السهل هي ربيعة الخناق عن القبائل المصابة بالجهة الأوروبية وهي جزء من اهالي عمان، ما يحمل عنوان الباي في سوريا، وكانت قبائل القبائل المصابة بقرية صحة البداء، وهي أخذ قلب رهبان الجنوبي يشبه الأوائل من الساحة. وتشتوط من قبيلة سي نين ببحرية صغيرة مثل سي أو غي7 علي باستو، ومن بينها الباي هشام زنتون وسطاء، وتوفوي على ميتو شارع ساحة في الرابعة بزينج ببوخذوابر انطلاقا وجزءا ميتو أو زناتين المقربة من المدينة.\n",
            "\n",
            "وكانت القبائل السهل هي باحرة عنصرية جميلة تقوم بتعيين اليهود ايقاف الخبار، وسحقت جهة القبائل قبلي\n",
            "======================================== SAMPLE 15 ========================================\n",
            "لي أليوميديو، طوروا مع الإلكترونات إلا أن البوليستريوس يمتزون بواسطة الكلامة تحت اللحوم في الخارج وأنظمة الهندسة الأولى.\n",
            "\n",
            "لها ست ضعف في البوليستريوس المقابلة أو المقاومة في الغالب كيو أو السءبومات بواسطة السجلاوية أو تقتصر على الأرجل لكي وسيلة لها أعلى ما ترتبط بهذه الضعف المطلوب. الثلج داخل الجسم استخدام المقاومة أو التحليل بالقشارة يمنع النزيف الأبجدي من الأرجل انفصالاً عن الترامول إلى جانب الويب والخدر وانخفاض أحوال لحوم لقمات الغرب. الأرجل التقليديون يشيرون إليه عداوة أو تحول طفولتهم استخداماً في حالة أقل عرضة لهم. الثلج الذي يضع فيه الأرجل هو يومين للسحب. وهو تمثيل قائمًا على بعض الثقوب والقيح والكنوص ورأس الأخر. ويمنع التعريفات الآخرين تقييد نقص الرأس الثبيت للطاقة والمالح.من التراضي أن تعاني التعاني من دار الأحماض الأمينة وشاهدها. على سبيل المثال، الثقوب نحن لا يمكن لراؤولولوس المكانة اسمها كيو \"إلينا المباني\"، وكنتيجة للاهتمام بأنه محتوى بمثابة اسم الثقوب، يتم اسم تحتوي رأس طاقة المر (غالبًا من الجلد للطائفة المراوح). ثباك الحجم أو الذبح يغطي مباشرة واضحة للسار، خاصةً وخاصةً على نتيجة لهذا النط\n",
            "======================================== SAMPLE 16 ========================================\n",
            "\" بالشرق الأقصى قصيلة ليكون لأنه الشرق الأبيض يحلق ما بين خط الماء \" ٌ\" ، \" الشرق الأسير\" يحاط بالأمراض التابعة على \" . موقعة تشبه هذه العيوب \" موقعة تشبه الامر اسم \" يحتوي على عيوب \" موقعة .\n",
            "\n",
            "يكون للمنبر أشكال عينية لكل المنقبرة من اتجاهين عتو وخبرة الدم ردا على حديد الفريد والبذور\n",
            "\n",
            "\n",
            "\n",
            "فرانك بنطي\n",
            "\n",
            "فرانك بنطي (8 فبراير 2018)، هو قائد سعودي للأطفال. وقد اعتمد في البرلمان في شمال فلوريا الشرقية للمعرفة الزراعية، كما قدم له هذا الفرانسيين، ووصف أهمية هذا الموقع بخصوصية عامة مكروه في الضفة الشرقية خلال المرفق الجغرافي.\n",
            "\n",
            "وحلى بعض الشؤون الإتقانية مسيحية قلبية، فقدت الحركة الدولية جزيرة بنطي العدسة المحرم له مستطيلة بشكل مائل على النطاف فإن الملابس ترافق في المغازلة، فإحدى بطولات الدولة أطلقه صفة عامة. وقدر ما يصل إليه هو لخبرة منشطة الكتاب -ختمة وعمارة على نطاف -إذا فطلب أطلقه أم تعود إمر أمين جقري الدولة.\n",
            "\n",
            "وقد سيتم استطاع قوة قصيرة حيث قامت كثيرا بمراجعات خاصة متوالية بهدم النطاف حتما عند درجات على الأطفال ثقافة (فرانك بنطي)، بالإضافة إلى متوالية أداء عصره وحمايته، كما قام بتوفيق ال\n",
            "======================================== SAMPLE 17 ========================================\n",
            "وتونبوليه مان\n",
            "\n",
            "اسْتونبوليه مان هو عازف بيانوسيستي وأول ميلا ونباتي فنلندي، ولد في 10 أكتوبر 1939 في نورث غرب غينزفيل. مسلم ملابس فنلندية، كما ساهم في إطار العنواني بالقبلة والفرعون المدمجون بلا وبحثاً عنه.\n",
            "\n",
            "\n",
            "جون ماسباروي غرامو يوهانسن\n",
            "\n",
            "جون ماسباروي غَرْامِوًاِكَ يوهَانُساً، لا يَزال يعرف الأصل بتمثيل كوريا الجنوبي من قبل جامعة غرام في جنوب ولاية القنيطرة (نرويجيا) سنة(1971) للمشاركة في ثقافة الشغد المُسلم، كما أن يمثل ثقافة معهد وقاهر للمسلمين البعيدين في مطعمة العالم العربي.\n",
            "\n",
            "\n",
            "حديث الإسكندرية\n",
            "\n",
            "تعتبر الحْدْيث الإسكْنْدرِيَّة، أو الحِدِيث الأَبْنِيْاتِ اللدَّاسية الجيولوجية النفطية النحوية المشعّية التي تحدث لِكلْ العالم بطريقة تحت الهنادق ( Sundayantisrace II).\n",
            "أن أهم ما يسمى أحيانا بالحِدِيث أو الأَبَنِيَات؟ فأوردت الأشجار وله القصص المذهب الصغير أو ما يصل إليه أحيانا، ويقوم ذلك ميقاتلتي الأشجار الغشاء الغربي وما إذا كانت ناجحة في ذلك مستمدة من المشاعر والتشبع في الطغاةالنجزية. وادعى هذا المحاضر في مواجهة الأشجار القاس الرطبة مثل الزيت العبودي الخاصة العطارة في أغلبيتها العامer.\n",
            "\n",
            "وسميت الحديث إذا نجح الأشغال الشريعة عبر الإنترنت بجذ\n",
            "Traceback (most recent call last):\n",
            "  File \"generate_unconditional_samples.py\", line 77, in <module>\n",
            "    fire.Fire(sample_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 468, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 672, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"generate_unconditional_samples.py\", line 69, in sample_model\n",
            "    out = sess.run(output)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrMhAYP9NAlg",
        "colab_type": "text"
      },
      "source": [
        "### Test encoder for standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGeYU6BSJaGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5a585fc5-8afc-4a90-b94a-1a1cc41f1121"
      },
      "source": [
        "%cd /content/gpt-2/src\n",
        "import os, json\n",
        "import model, encoder\n",
        "enc = encoder.get_encoder('argpt')\n",
        "hparams = model.default_hparams()\n",
        "with open(os.path.join('models', 'argpt', 'hparams.json')) as f:\n",
        "    hparams.override_from_dict(json.load(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2/src\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:147: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyOo5DT4Kxql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "7e8a2dda-f534-462f-8acf-cb758a32f984"
      },
      "source": [
        "enc.encode('عبور الزهرة – إعدام فرعون')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[44690,\n",
              " 39848,\n",
              " 30335,\n",
              " 26897,\n",
              " 28981,\n",
              " 148,\n",
              " 110,\n",
              " 29519,\n",
              " 26897,\n",
              " 45632,\n",
              " 784,\n",
              " 17550,\n",
              " 98,\n",
              " 44690,\n",
              " 38843,\n",
              " 12919,\n",
              " 25405,\n",
              " 18923,\n",
              " 223,\n",
              " 26897,\n",
              " 44690,\n",
              " 30335,\n",
              " 23338]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPdwKoIFLGfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b777b3a-deed-4c61-9eb1-64dfdf1220a7"
      },
      "source": [
        "enc.decode([29519])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ه'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK9CqBo0Lcp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a vocab.txt\n",
        "import json\n",
        "vop = open('/content/vocab.json', 'w')\n",
        "sv = {}\n",
        "for k in enc.decoder.keys():\n",
        "  sv[enc.decoder[k]] = k\n",
        "  #vop.write(enc.decoder[k] + \"\\n\")\n",
        "#vop.write(\"[egyptian]\\n[gulf]\\n[levantine]\\n[maghrebi]\\n[msa]\")\n",
        "vop.write(json.dumps(sv, separators=(',', ':')))\n",
        "vop.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLR4Ge-r1Z_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1041f12e-d076-46fa-eb52-f34c7bf74abf"
      },
      "source": [
        "len(enc.decoder.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47nF8H6UNE6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cp /content/vocab.txt /content/drive/My\\ Drive/mlin/argpt/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}